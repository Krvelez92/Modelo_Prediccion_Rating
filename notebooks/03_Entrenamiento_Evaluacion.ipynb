{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c8cfb648",
   "metadata": {},
   "source": [
    "# Librerias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9c7d5c93",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pickle\n",
    "from sklearn.metrics import mean_absolute_error, mean_absolute_percentage_error, mean_squared_error, r2_score\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score\n",
    "from sklearn.preprocessing import PolynomialFeatures, MinMaxScaler, StandardScaler\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso, ElasticNet\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "import xgboost\n",
    "from sklearn.svm import SVR\n",
    "\n",
    "pd.options.display.max_columns = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "368b0d99",
   "metadata": {},
   "outputs": [],
   "source": [
    "''' \n",
    "Lectura de datos de restaurantes de Madrid.\n",
    "'''\n",
    "restaurantes = pd.read_csv('../data/processed/restaurantes.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "233df388",
   "metadata": {},
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "21735c89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 16 candidates, totalling 160 fits\n",
      "Pipeline(steps=[('scaler', 'passthrough'),\n",
      "                ('classifier',\n",
      "                 RandomForestRegressor(max_depth=10, min_samples_leaf=30,\n",
      "                                       random_state=42))])\n",
      "-5.052585049215095\n",
      "{'classifier': RandomForestRegressor(random_state=42), 'classifier__bootstrap': True, 'classifier__max_depth': 10, 'classifier__min_samples_leaf': 30, 'classifier__n_estimators': 100, 'scaler': 'passthrough'}\n"
     ]
    }
   ],
   "source": [
    "X = restaurantes[['serves_breakfast', \n",
    "                  'parados', \n",
    "                  'dur_media_credito_viviendas', \n",
    "                  'poblacion_80_mas',\n",
    "                  'poblacion_china',\n",
    "                  'pct_crecimiento_demografico',\n",
    "                  'rating_mean',\n",
    "                  'poblacion_italia',\n",
    "                  'user_ratings_mean',\n",
    "                  'price_level',\n",
    "                  'tipo_cocina_encoder',\n",
    "                  'cod_barrio'\n",
    "                  ]]\n",
    "\n",
    "y = restaurantes['y']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "pipe = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('classifier', RandomForestRegressor(random_state=42))])\n",
    "\n",
    "rf_params = {\n",
    "    'scaler': [MinMaxScaler(), 'passthrough'],\n",
    "    'classifier': [RandomForestRegressor(random_state=42)],\n",
    "    'classifier__max_depth': [7, 10],\n",
    "    'classifier__min_samples_leaf': [20, 30],\n",
    "    'classifier__n_estimators':[100, 150],\n",
    "    'classifier__bootstrap':[True]\n",
    "}\n",
    "\n",
    "\n",
    "search_space = [\n",
    "    rf_params\n",
    "]\n",
    "\n",
    "clf = GridSearchCV(estimator = pipe,\n",
    "                  param_grid = search_space,\n",
    "                  scoring='neg_mean_absolute_error',\n",
    "                  cv = 10,\n",
    "                  n_jobs=-1,\n",
    "                  verbose=2)\n",
    "\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "print(clf.best_estimator_)\n",
    "print(clf.best_score_)\n",
    "print(clf.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "3240432b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.07442303 0.02984183 0.02504117 0.02122761 0.02760644 0.0610642\n",
      " 0.01982765 0.23187436 0.49863608 0.01045762]\n",
      "Index(['serves_breakfast', 'parados', 'dur_media_credito_viviendas',\n",
      "       'poblacion_80_mas', 'pct_crecimiento_demografico', 'rating_mean',\n",
      "       'poblacion_italia', 'user_ratings_mean', 'price_level',\n",
      "       'tipo_cocina_encoder'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(clf.best_estimator_.named_steps['classifier'].feature_importances_)\n",
    "print(X.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "425dbeba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE test 5.213517838257014\n",
      "MAPE test 0.4134135223207572\n",
      "MSE test 45.28228613087645\n",
      "RMSE test 6.7292114048286855\n",
      "R2 score 0.3281314612176084\n"
     ]
    }
   ],
   "source": [
    "best1 = clf.best_estimator_\n",
    "predictions_best1 = best1.predict(X_test)\n",
    "\n",
    "print(\"MAE test\", mean_absolute_error(y_test, predictions_best1))\n",
    "print(\"MAPE test\", mean_absolute_percentage_error(y_test, predictions_best1))\n",
    "print(\"MSE test\", mean_squared_error(y_test, predictions_best1))\n",
    "print(\"RMSE test\", mean_squared_error(y_test, predictions_best1)**(1/2))\n",
    "print(\"R2 score\", r2_score(y_test, predictions_best1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "186c3f2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = '../models/1_randomforest_model.pkl'\n",
    "\n",
    "with open(filename, 'wb') as archivo_salida:\n",
    "    pickle.dump(best1, archivo_salida)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b054f4e7",
   "metadata": {},
   "source": [
    "# Reg Lineales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "448cbcf3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 562 candidates, totalling 5620 fits\n",
      "Pipeline(steps=[('poly', PolynomialFeatures()), ('scaler', MinMaxScaler()),\n",
      "                ('classifier', Ridge(alpha=0.25))])\n",
      "-5.081940554111285\n",
      "{'classifier': Ridge(), 'classifier__alpha': 0.25, 'poly__degree': 2, 'scaler': MinMaxScaler()}\n"
     ]
    }
   ],
   "source": [
    "X = restaurantes[['serves_breakfast', \n",
    "                  'parados', \n",
    "                  'dur_media_credito_viviendas', \n",
    "                  'poblacion_80_mas',\n",
    "                  'poblacion_china',\n",
    "                  'pct_crecimiento_demografico',\n",
    "                  'rating_mean',\n",
    "                  'poblacion_italia',\n",
    "                  'user_ratings_mean',\n",
    "                  'price_level']]\n",
    "\n",
    "y = restaurantes['y']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "pipe = Pipeline([\n",
    "    ('poly', PolynomialFeatures()),\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('classifier', LinearRegression())])\n",
    "\n",
    "linear_params = {\n",
    "    'poly__degree':[1],\n",
    "    'scaler':[MinMaxScaler(), StandardScaler()],\n",
    "    'classifier': [LinearRegression()]\n",
    "}\n",
    "\n",
    "regularizacion_params = {\n",
    "    'poly__degree':[1, 2, 3, 4, 5],\n",
    "    'scaler': [MinMaxScaler(), StandardScaler()],\n",
    "    'classifier': [Ridge(), Lasso()],\n",
    "    'classifier__alpha': [0.25, 0,75, 0.80, 0.90, 1, 100]\n",
    "}\n",
    "\n",
    "elastic_param = {\n",
    "    'poly__degree':[1, 2, 3, 4, 5],\n",
    "    'scaler': [MinMaxScaler(), StandardScaler()],\n",
    "    'classifier': [ElasticNet()],\n",
    "    'classifier__alpha': [0.25, 0,75, 0.80, 0.90, 1, 100],\n",
    "    'classifier__l1_ratio': [0.1, 0.25, 0.50, 0.75, 0.80, 1]\n",
    "}\n",
    "\n",
    "search_space = [\n",
    "    linear_params,\n",
    "    regularizacion_params,\n",
    "    elastic_param\n",
    "]\n",
    "\n",
    "clf2 = GridSearchCV(estimator = pipe,\n",
    "                  param_grid = search_space,\n",
    "                  scoring='neg_mean_absolute_error',\n",
    "                  cv = 10,\n",
    "                  n_jobs=-1,\n",
    "                  verbose=2)\n",
    "\n",
    "clf2.fit(X_train, y_train)\n",
    "\n",
    "print(clf2.best_estimator_)\n",
    "print(clf2.best_score_)\n",
    "print(clf2.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "6d1599ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE test 5.209969983609404\n",
      "MAPE test 0.41869564397943093\n",
      "MSE test 44.72980831554107\n",
      "RMSE test 6.688034712495224\n",
      "R2 score 0.33632876074056617\n"
     ]
    }
   ],
   "source": [
    "best2 = clf2.best_estimator_\n",
    "predictions_best2 = best2.predict(X_test)\n",
    "\n",
    "print(\"MAE test\", mean_absolute_error(y_test, predictions_best2))\n",
    "print(\"MAPE test\", mean_absolute_percentage_error(y_test, predictions_best2))\n",
    "print(\"MSE test\", mean_squared_error(y_test, predictions_best2))\n",
    "print(\"RMSE test\", mean_squared_error(y_test, predictions_best2)**(1/2))\n",
    "print(\"R2 score\", r2_score(y_test, predictions_best2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "c52858ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = '../models/2_ridge_model.pkl'\n",
    "\n",
    "with open(filename, 'wb') as archivo_salida:\n",
    "    pickle.dump(best2, archivo_salida)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60982e68",
   "metadata": {},
   "source": [
    "# Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "9264d03e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 36 candidates, totalling 360 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('classifier',\n",
      "                 GradientBoostingRegressor(learning_rate=0.25,\n",
      "                                           min_samples_leaf=30,\n",
      "                                           random_state=42))])\n",
      "-5.1158186135385435\n",
      "{'classifier': GradientBoostingRegressor(random_state=42), 'classifier__learning_rate': 0.25, 'classifier__max_depth': 3, 'classifier__min_samples_leaf': 30, 'classifier__n_estimators': 100, 'scaler': StandardScaler()}\n"
     ]
    }
   ],
   "source": [
    "X = restaurantes[['serves_breakfast', \n",
    "                  'parados', \n",
    "                  'dur_media_credito_viviendas', \n",
    "                  'poblacion_80_mas',\n",
    "                  'poblacion_china',\n",
    "                  'pct_crecimiento_demografico',\n",
    "                  'rating_mean',\n",
    "                  'poblacion_italia',\n",
    "                  'user_ratings_mean',\n",
    "                  'price_level',\n",
    "                  'tipo_cocina_encoder',\n",
    "                  'cod_barrio'\n",
    "                  ]]\n",
    "\n",
    "y = restaurantes['y']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "pipe = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('classifier', GradientBoostingRegressor(random_state=42))])\n",
    "\n",
    "gboost_param = {\n",
    "    'scaler': [StandardScaler(), 'passthrough'],\n",
    "    'classifier': [GradientBoostingRegressor(random_state=42)],\n",
    "    'classifier__learning_rate': [0.25, 0.3, 0.5],\n",
    "    'classifier__max_depth': [3, 4],\n",
    "    'classifier__min_samples_leaf': [20, 30, 40],\n",
    "    'classifier__n_estimators':[100]\n",
    "}\n",
    "\n",
    "\n",
    "search_space = [\n",
    "    gboost_param\n",
    "]\n",
    "\n",
    "clf3 = GridSearchCV(estimator = pipe,\n",
    "                  param_grid = search_space,\n",
    "                  scoring='neg_mean_absolute_error',\n",
    "                  cv = 10,\n",
    "                  n_jobs=-1,\n",
    "                  verbose=3)\n",
    "\n",
    "clf3.fit(X_train, y_train)\n",
    "\n",
    "print(clf3.best_estimator_)\n",
    "print(clf3.best_score_)\n",
    "print(clf3.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "275552b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.07065508 0.02601208 0.01502961 0.02211229 0.00401168 0.02467589\n",
      " 0.1099545  0.03062598 0.22621286 0.42669326 0.02886445 0.01515232]\n",
      "Index(['serves_breakfast', 'parados', 'dur_media_credito_viviendas',\n",
      "       'poblacion_80_mas', 'poblacion_china', 'pct_crecimiento_demografico',\n",
      "       'rating_mean', 'poblacion_italia', 'user_ratings_mean', 'price_level',\n",
      "       'tipo_cocina_encoder', 'cod_barrio'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(clf3.best_estimator_.named_steps['classifier'].feature_importances_)\n",
    "print(X.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "655efd5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE test 5.27140560689094\n",
      "MAPE test 0.4081054046113165\n",
      "MSE test 46.29318811759027\n",
      "RMSE test 6.803909767008251\n",
      "R2 score 0.31313236778176456\n"
     ]
    }
   ],
   "source": [
    "best3 = clf3.best_estimator_\n",
    "predictions_best3 = best3.predict(X_test)\n",
    "\n",
    "print(\"MAE test\", mean_absolute_error(y_test, predictions_best3))\n",
    "print(\"MAPE test\", mean_absolute_percentage_error(y_test, predictions_best3))\n",
    "print(\"MSE test\", mean_squared_error(y_test, predictions_best3))\n",
    "print(\"RMSE test\", mean_squared_error(y_test, predictions_best3)**(1/2))\n",
    "print(\"R2 score\", r2_score(y_test, predictions_best3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "67aba27e",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = '../models/3_gradient_boost_model.pkl'\n",
    "\n",
    "with open(filename, 'wb') as archivo_salida:\n",
    "    pickle.dump(best3, archivo_salida)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7fb2275",
   "metadata": {},
   "source": [
    "# Xboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "4aeab6d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 108 candidates, totalling 1080 fits\n",
      "Pipeline(steps=[('scaler', MinMaxScaler()),\n",
      "                ('classifier',\n",
      "                 XGBRegressor(base_score=None, booster=None, callbacks=None,\n",
      "                              colsample_bylevel=None, colsample_bynode=None,\n",
      "                              colsample_bytree=None, device=None,\n",
      "                              early_stopping_rounds=None,\n",
      "                              enable_categorical=False, eval_metric=None,\n",
      "                              feature_types=None, feature_weights=None,\n",
      "                              gamma=None, grow_policy=None,\n",
      "                              importance_type=None,\n",
      "                              interaction_constraints=None, learning_rate=0.25,\n",
      "                              max_bin=None, max_cat_threshold=None,\n",
      "                              max_cat_to_onehot=None, max_delta_step=None,\n",
      "                              max_depth=4, max_leaves=None, min_child_weight=5,\n",
      "                              missing=nan, monotone_constraints=None,\n",
      "                              multi_strategy=None, n_estimators=100,\n",
      "                              n_jobs=None, num_parallel_tree=None, ...))])\n",
      "-5.2319797492254425\n",
      "{'classifier': XGBRegressor(base_score=None, booster=None, callbacks=None,\n",
      "             colsample_bylevel=None, colsample_bynode=None,\n",
      "             colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "             enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "             feature_weights=None, gamma=None, grow_policy=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_bin=None, max_cat_threshold=None,\n",
      "             max_cat_to_onehot=None, max_delta_step=None, max_depth=None,\n",
      "             max_leaves=None, min_child_weight=None, missing=nan,\n",
      "             monotone_constraints=None, multi_strategy=None, n_estimators=None,\n",
      "             n_jobs=None, num_parallel_tree=None, ...), 'classifier__learning_rate': 0.25, 'classifier__max_depth': 4, 'classifier__min_child_weight': 5, 'classifier__n_estimators': 100, 'scaler': MinMaxScaler()}\n"
     ]
    }
   ],
   "source": [
    "X = restaurantes[['serves_breakfast', \n",
    "                  'parados', \n",
    "                  'dur_media_credito_viviendas', \n",
    "                  'poblacion_80_mas',\n",
    "                  'poblacion_china',\n",
    "                  'pct_crecimiento_demografico',\n",
    "                  'rating_mean',\n",
    "                  'poblacion_italia',\n",
    "                  'user_ratings_mean',\n",
    "                  'price_level',\n",
    "                  'tipo_cocina_encoder',\n",
    "                  'cod_barrio'\n",
    "                  ]]\n",
    "\n",
    "y = restaurantes['y']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "pipe = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('classifier', xgboost.XGBRegressor())])\n",
    "\n",
    "xboost_param = {\n",
    "    'scaler': [MinMaxScaler(), StandardScaler(), 'passthrough'],\n",
    "    'classifier': [xgboost.XGBRegressor()],\n",
    "    'classifier__learning_rate': [0.25, 0.75, 1],\n",
    "    'classifier__max_depth': [4, 5, 6, 7],\n",
    "    'classifier__min_child_weight': [4, 5, 7],\n",
    "    'classifier__n_estimators':[100]\n",
    "}\n",
    "\n",
    "\n",
    "search_space = [\n",
    "    xboost_param\n",
    "]\n",
    "\n",
    "clf4 = GridSearchCV(estimator = pipe,\n",
    "                  param_grid = search_space,\n",
    "                  scoring='neg_mean_absolute_error',\n",
    "                  cv = 10,\n",
    "                  n_jobs=-1,\n",
    "                  verbose=3)\n",
    "\n",
    "clf4.fit(X_train, y_train)\n",
    "\n",
    "print(clf4.best_estimator_)\n",
    "print(clf4.best_score_)\n",
    "print(clf4.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "13f5b0d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.11709094 0.02775789 0.02901516 0.02960814 0.0353903  0.03775423\n",
      " 0.02490809 0.03277757 0.04551588 0.5713765  0.02802337 0.02078198]\n",
      "Index(['serves_breakfast', 'parados', 'dur_media_credito_viviendas',\n",
      "       'poblacion_80_mas', 'poblacion_china', 'pct_crecimiento_demografico',\n",
      "       'rating_mean', 'poblacion_italia', 'user_ratings_mean', 'price_level',\n",
      "       'tipo_cocina_encoder', 'cod_barrio'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(clf4.best_estimator_.named_steps['classifier'].feature_importances_)\n",
    "print(X.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "d54b5ad2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE test 5.321078056766567\n",
      "MAPE test 0.3989015305796611\n",
      "MSE test 48.150308346763005\n",
      "RMSE test 6.939042322018436\n",
      "R2 score 0.2855776491195654\n"
     ]
    }
   ],
   "source": [
    "best4 = clf4.best_estimator_\n",
    "predictions_best4 = best4.predict(X_test)\n",
    "\n",
    "print(\"MAE test\", mean_absolute_error(y_test, predictions_best4))\n",
    "print(\"MAPE test\", mean_absolute_percentage_error(y_test, predictions_best4))\n",
    "print(\"MSE test\", mean_squared_error(y_test, predictions_best4))\n",
    "print(\"RMSE test\", mean_squared_error(y_test, predictions_best4)**(1/2))\n",
    "print(\"R2 score\", r2_score(y_test, predictions_best4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "8931ba33",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = '../models/4_xboost_model.pkl'\n",
    "\n",
    "with open(filename, 'wb') as archivo_salida:\n",
    "    pickle.dump(best4, archivo_salida)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47e15fbc",
   "metadata": {},
   "source": [
    "# SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "5b238b23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 720 candidates, totalling 7200 fits\n",
      "Pipeline(steps=[('scaler', MinMaxScaler()),\n",
      "                ('classifier',\n",
      "                 SVR(C=10, degree=2, kernel='poly', max_iter=50000))])\n",
      "-5.017888992178857\n",
      "{'classifier': SVR(), 'classifier__C': 10, 'classifier__degree': 2, 'classifier__gamma': 'scale', 'classifier__kernel': 'poly', 'classifier__max_iter': 50000, 'scaler': MinMaxScaler()}\n"
     ]
    }
   ],
   "source": [
    "X = restaurantes[['serves_breakfast', \n",
    "                  'parados', \n",
    "                  'dur_media_credito_viviendas', \n",
    "                  'poblacion_80_mas',\n",
    "                  'poblacion_china',\n",
    "                  'pct_crecimiento_demografico',\n",
    "                  'rating_mean',\n",
    "                  'poblacion_italia',\n",
    "                  'user_ratings_mean',\n",
    "                  'price_level',\n",
    "                  'tipo_cocina_encoder',\n",
    "                  'cod_barrio'\n",
    "                  ]]\n",
    "\n",
    "y = restaurantes['y']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "pipe = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('classifier', SVR())])\n",
    "\n",
    "SVR_param = {\n",
    "    'scaler': [MinMaxScaler(), StandardScaler(), 'passthrough'],\n",
    "    'classifier': [SVR()],\n",
    "    'classifier__kernel': ['linear', 'poly', 'rbf'],\n",
    "    'classifier__gamma': ['scale', 'auto'],\n",
    "    'classifier__degree': [2, 3, 4, 5],\n",
    "    'classifier__C':[0.5, 1, 10, 50, 100],\n",
    "    'classifier__max_iter': [10000, 50000]\n",
    "}\n",
    "\n",
    "\n",
    "search_space = [\n",
    "    SVR_param\n",
    "]\n",
    "\n",
    "clf5 = GridSearchCV(estimator = pipe,\n",
    "                  param_grid = search_space,\n",
    "                  scoring='neg_mean_absolute_error',\n",
    "                  cv = 10,\n",
    "                  n_jobs=-1,\n",
    "                  verbose=3)\n",
    "\n",
    "clf5.fit(X_train, y_train)\n",
    "\n",
    "print(clf5.best_estimator_)\n",
    "print(clf5.best_score_)\n",
    "print(clf5.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "13e29504",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE test 5.107285093006351\n",
      "MAPE test 0.43212798050297707\n",
      "MSE test 45.17899883149742\n",
      "RMSE test 6.7215324764146915\n",
      "R2 score 0.3296639696847825\n"
     ]
    }
   ],
   "source": [
    "best5 = clf5.best_estimator_\n",
    "predictions_best5 = best5.predict(X_test)\n",
    "\n",
    "print(\"MAE test\", mean_absolute_error(y_test, predictions_best5))\n",
    "print(\"MAPE test\", mean_absolute_percentage_error(y_test, predictions_best5))\n",
    "print(\"MSE test\", mean_squared_error(y_test, predictions_best5))\n",
    "print(\"RMSE test\", mean_squared_error(y_test, predictions_best5)**(1/2))\n",
    "print(\"R2 score\", r2_score(y_test, predictions_best5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "2e9bb66d",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = '../models/5_srv_model.pkl'\n",
    "\n",
    "with open(filename, 'wb') as archivo_salida:\n",
    "    pickle.dump(best5, archivo_salida)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eae7bead",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
